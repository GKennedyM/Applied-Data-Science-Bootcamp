{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347742aa",
   "metadata": {},
   "source": [
    "## Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8b20911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db2af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "input=cv2.imread('input.jpg')\n",
    "cv2.imshow('Hello World',input)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890732f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "input=cv2.imread('input.jpg')\n",
    "cv2.imshow('Hello World',input)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28448cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import cv2\n",
    "# input=cv2.imread('input.jpg')\n",
    "# cv2.imshow('Hello World',input)\n",
    "# cv2.waitKey()\n",
    "\n",
    "# gray_images=cv2.cvtColor(input, cv2.COLOR_BGR2GRAY)\n",
    "# cv2.imshow('BW image',gray_image)\n",
    "# cv2.waitKey()\n",
    "\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3379414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "input=cv2.imread('input.jpg')\n",
    "cv2.imshow('Hello World',input)\n",
    "cv2.waitKey()\n",
    "\n",
    "gray_image=cv2.cvtColor(input,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('BW image',gray_image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2446d9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 1245, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20645138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=cv2.imread('input.jpg')\n",
    "height,width=image.shape[:2]\n",
    "\n",
    "sobel_x=cv2.Sobel(image,cv2.CV_64F,0,1,ksize=5)\n",
    "sobel_y=cv2.Sobel(image,cv2.CV_64F,1,0,ksize=5)\n",
    "\n",
    "cv2.imshow('Rotated Image',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('Sobel X',sobel_x)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('Sobel Y',sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR=cv2.bitwise_or(sobel_x,sobel_y)\n",
    "cv2.imshow('Sobel_OR',sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian=cv2.Laplacian(image, cv2.CV_64F)\n",
    "cv2.imshow('Laplacian',laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny=cv2.Canny(image,50,120)\n",
    "cv2.imshow('Canny',canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d951b805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def sketch(image):\n",
    "    img_gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "    canny_edges = cv2.Canny(img_gray_blur,10,70)\n",
    "    # ret,mask = cv2.threshold(canny_edges,70,255,cv2.THRESH_BINARY_INV)\n",
    "    ret,mask = cv2.threshold(canny_edges,70,255,cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    cv2.imshow('Our Live Sketcher',sketch(frame))\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f207f346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    cv2.imshow('Our Live Sketcher',frame)\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0344afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('WaldoBeach.jpg')\n",
    "\n",
    "cv2.imshow('Where is Waldo',image)\n",
    "cv2.waitKey(0)\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "template=cv2.imread('waldo.jpg',0)\n",
    "\n",
    "result=cv2.matchTemplate(gray,template,cv2.TM_CCOEFF)\n",
    "minVal, maxVal,minLoc,maxLoc=cv2.minMaxLoc(result)\n",
    "\n",
    "top_left=maxLoc\n",
    "bottom_right=(top_left[0]+50,top_left[1]+50)\n",
    "#bottom_right=(top_left[0]+50,top_left[1]+50)\n",
    "cv2.rectangle (image,top_left,bottom_right,(0,0,255),5)\n",
    "\n",
    "cv2.imshow('Where is Waldo',image)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f402ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "ret1,frame1=cap.read()\n",
    "ret2,frame2=cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray=cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur=cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur=cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "    \n",
    "    diff=cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    \n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1=frame2\n",
    "    \n",
    "    ret,frame2=cap.read()\n",
    "    \n",
    "    if not ret:    \n",
    "        cap.release()\n",
    "        break\n",
    "        \n",
    "    key=cv2.waitKey(10)\n",
    "    if key==ord('q'):\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "315b5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap=cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "ret1, frame1 = cap.read()\n",
    "ret2, frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)    \n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray, (21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray, (21,21),0)        \n",
    "    \n",
    "    diff=cv2.absdiff(frame1_blur, frame2_blur)\n",
    "    \n",
    "    thresh=cv2.threshold(diff, 20, 255, cv2.THRESH_BINARY)[1]\n",
    "    final=cv2.dilate(thresh, None, iterations=2)\n",
    "    \n",
    "    masked=cv2.bitwise_and(frame1, frame1, mask=thresh)\n",
    "    \n",
    "    white_pixels = np.sum(thresh)/255\n",
    "    \n",
    "    rows, cols=thresh.shape\n",
    "    total=rows*cols\n",
    "    \n",
    "    if white_pixels > 0.01 * total:\n",
    "        font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame1, \"Movement Detected\", (10,50), font, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"Motion\", frame1)\n",
    "    frame1 = frame2\n",
    "    \n",
    "    ret,frame2=cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "  \n",
    "    key=cv2.waitKey(10)\n",
    "    if key==ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc5952f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_14804\\1098334121.py:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# print(face_classifier)\n",
    "image=cv2.imread('myself.jpg')\n",
    "gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces=face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "    \n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h),(127,0,255),2)\n",
    "    cv2.imshow(\"Face Detection\",image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23909b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_14804\\3616149407.py:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img=cv2.imread('myself.jpg')\n",
    "gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces=face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "if faces is ():\n",
    "    print(\"No faces / eye found\")\n",
    "    \n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h),(127,0,255),2)\n",
    "    cv2.imshow(\"Face Detection\",img)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    \n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex,ey), (ex+ew,ey+eh),(255,255,0),2)\n",
    "        cv2.imshow(\"Eye Detection\",img)\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1cb50be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\gilbe\\AppData\\Local\\Temp\\ipykernel_14804\\2238160903.py:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    # once gri renge cevirelim\n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return img\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        x = x-50\n",
    "        w = w+50\n",
    "        y = y-50\n",
    "        h = h+50\n",
    "        \n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        sleep(.05)\n",
    "      \n",
    "\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex,ey), (ex+ew,ey+eh),(0,0,255),2)\n",
    "\n",
    "    img=cv2.flip(img,1)\n",
    "    return img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow('Face Extractor',face_detector(frame))\n",
    "    if cv2.waitKey(1)==13: # 13 is Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924bbc63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c9b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
